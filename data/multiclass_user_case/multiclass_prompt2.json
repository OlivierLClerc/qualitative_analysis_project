{
    "selected_columns": [
        "r\u00e9ponse_attendue",
        "r\u00e9ponse_llm",
        "iteration"
    ],
    "column_renames": {
        "r\u00e9ponse_attendue": "r\u00e9ponse_attendue",
        "r\u00e9ponse_llm": "r\u00e9ponse_llm",
        "iteration": "iteration"
    },
    "column_descriptions": {
        "r\u00e9ponse_attendue": "Un passage de r\u00e9ponse consid\u00e9r\u00e9e comme satisfaisante",
        "r\u00e9ponse_llm": "La r\u00e9ponse fournie par le LLM, \u00e0 juger",
        "iteration": "Identifiant"
    },
    "codebook": "T\u00e2che d\u2019\u00e9valuation :\n\u00c9valuer si la r\u00e9ponse_llm r\u00e9pond ad\u00e9quatement, c'est \u00e0 dire qu'elle correspond \u00e0 la r\u00e9ponse attendue, en utilisant l\u2019\u00e9chelle suivante :\n\n0 : La r\u00e9ponse g\u00e9n\u00e9r\u00e9e ne permet pas du tout de r\u00e9pondre \u00e0 la question pos\u00e9e (hors sujet, incompl\u00e8te ou incorrecte).\n1 : La r\u00e9ponse g\u00e9n\u00e9r\u00e9e permet difficilement de r\u00e9pondre \u00e0 la question, car elle est vague, trop ou pas assez d\u00e9taill\u00e9e.\n2 : La r\u00e9ponse g\u00e9n\u00e9r\u00e9e permet de r\u00e9pondre clairement \u00e0 la question.",
    "examples": "",
    "selected_fields": [
        "Reasoning",
        "Classification"
    ],
    "selected_model": "gpt-4o",
    "annotation_columns": [
        "Rater_Oli"
    ],
    "label_column": "Classification",
    "label_type": "Integer",
    "text_columns": [
        "r\u00e9ponse_attendue",
        "r\u00e9ponse_llm"
    ]
}