# QUALITATIVE_ANALYSIS_PROJECT

A **Python-based toolkit** for qualitative data analysis using **Large Language Models (LLMs)**.

This toolkit provides two modes for automatic annotation of qualitative data:

1. **No-Code Mode** â†’ Use the interactive **Streamlit** web app.  
2. **Low-Code Mode** â†’ Use the provided **Jupyter/Colab notebooks** for more customizable workflows.

---

## ğŸš€ Running without installation

### **Use the streamlit server**

Click the link below to run the web app. 
ğŸ‘‰ [Run the Qualitative Analysis App](https://flowanalysis.streamlit.app/)

### **Run in Google Colab**

Click the badge below to run the notebook directly in **Google Colab**:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/OlivierLClerc/qualitative_analysis_project/blob/master/notebooks/notebook_sequential_binary_colab.ipynb)

## **Run Locally (Full Control)**

If you prefer to run the analysis directly on your machine, follow those installation steps.

1. Clone the repository.

```bash
git clone https://github.com/your-username/qualitative_analysis_project.git
cd qualitative_analysis_project
```
2. Create a Virtual Environment

```bash
conda create -n qualitative_analysis python=3.10
conda activate qualitative_analysis
```

3. Install the required packages:

```bash
pip install -r requirements.txt
```
4. Put your API credential.

Copy or rename `.env.example` to `.env`. Populate it with your LLM credentials (e.g., Azure or Together keys, endpoints).

Example:

```bash
AZURE_API_KEY="your_azure_api_key"
AZURE_OPENAI_ENDPOINT="https://your-endpoint.openai.azure.com/"
AZURE_API_VERSION="2023-05-15"
```

If youâ€™re using Together, set:

```bash
TOGETHER_API_KEY="your_together_api_key"
```

## Usage

The project offers two primary usage modes:

1. [Streamlit app](app.py): Use the interactive GUI for classification workflows.
2. [Notebooks](notebooks): Run classification workflows in Jupyter Notebooks.

### Usage 1: Streamlit app

```bash
streamlit run app.py
```
This launches a browser-based interface to upload data, configure LLMs, run analyses, and download results.

### Usage 2: Notebooks

The notebooks contain the classification workflows for each criterion:

- [Binary criterion](notebooks/notebook_binary.ipynb).
- [Multiclass criterion](notebooks/notebook_multiclass.ipynb).
- [Sequential binary criterion](notebooks/notebook_sequential_binary.ipynb).

## Project Structure

```bash
QUALITATIVE_ANALYSIS_PROJECT
â”œâ”€â”€ codebook
â”‚   â”œâ”€â”€ binary_codebook.txt
â”‚   â””â”€â”€ multiclass_codebook.txt
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ multiclass_KA.csv
â”‚   â”œâ”€â”€ multiclass_MC.csv
â”‚   â”œâ”€â”€ multiclass_sample_chem.csv
â”‚   â”œâ”€â”€ multiclass_sample.csv
â”‚   â””â”€â”€ sequential_binary_sample.csv
â”œâ”€â”€ notebooks
â”‚   â”œâ”€â”€ notebook_binary.ipynb
â”‚   â”œâ”€â”€ notebook_multiclass.ipynb
â”‚   â””â”€â”€ notebook_sequential_binary.ipynb
â”œâ”€â”€ qualitative_analysis
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ cost_estimation.py
â”‚   â”œâ”€â”€ data_processing.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ model_interaction.py
â”‚   â”œâ”€â”€ notebooks_functions.py
â”‚   â”œâ”€â”€ parsing.py
â”‚   â””â”€â”€ prompt_construction.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ app.py
â”œâ”€â”€ mypy.ini
â””â”€â”€ README.md
```
## ğŸ“‚ Main Files and folders

### `app.py`
A Streamlit app providing a GUI workflow for uploading data, configuring LLMs, classifying text, and optionally comparing with external judgments.

### `notebooks/`
Contains Jupyter notebooks demonstrating how to use the library for:
- Binary classification
- Multiclass classification
- Sequential binary classification

### `data/`
Holds CSV samples (for various classification scenarios), plus an `outputs/` subfolder where processed results can be saved.

### `qualitative_analysis/`
The main Python package, housing modules

### `codebook/`
Contains human-readable text files defining classification rules or codebooks (binary/multiclass).

## ğŸ“„ Other Files

- **`.env`** â€“ Environment variables for sensitive credentials (e.g., API keys, endpoints).
- **`.pre-commit-config.yaml`** â€“ Config for pre-commit hooks (linting, formatting, etc.).
- **`mypy.ini`** â€“ Configuration for static type checks (mypy).

## ğŸ¤ Contributing

- **Coding Style**: This repo uses type hints and docstrings heavily (see `mypy.ini` for static checks).
- **Pre-Commit Hooks**: Use `.pre-commit-config.yaml` for linting/formatting. Install pre-commit hooks:

    ```bash
    pre-commit install
    ```

- **Pull Requests**: Please branch off `main` or `dev`, open a PR, and ensure you pass all lint/tests.

## ğŸ“œ License


## ğŸ“š Acknowledgments / References

- OpenAI / Azure Docs
- Together AI Documentation
- Streamlit Official Docs
- Pandas User Guide
